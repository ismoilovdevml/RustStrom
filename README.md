<div align="center">

# ‚ö° RustStrom

### High-Performance Load Balancer Built with Rust

**Proven Performance - Outperforms HAProxy** | Zero-Downtime Deployments | Production-Ready

[![Build Status](https://img.shields.io/github/actions/workflow/status/ismoilovdevml/RustStrom/rust.yml?branch=main)](https://github.com/ismoilovdevml/RustStrom/actions)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-0.1.0-green.svg)](https://github.com/ismoilovdevml/RustStrom/releases)
[![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)](https://www.rust-lang.org)
[![GitHub Stars](https://img.shields.io/github/stars/ismoilovdevml/RustStrom?style=social)](https://github.com/ismoilovdevml/RustStrom/stargazers)

[Quick Start](#-quick-start) ‚Ä¢ [Documentation](#-configuration-guide) ‚Ä¢ [Benchmarks](#-benchmarks) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üìñ Table of Contents

- [Features](#-features)
- [Performance Comparison](#-performance-comparison)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Configuration Guide](#-configuration-guide)
- [Load Balancing Algorithms](#-load-balancing-algorithms)
- [Middleware Guide](#-middleware-guide)
- [Health Checking](#-health-checking)
- [Monitoring](#-monitoring)
- [Benchmarks](#-benchmarks)
- [Production Deployment](#-production-deployment)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ‚ú® Features

RustStrom is a blazing-fast, production-ready load balancer that outperforms HAProxy with 15.5% better tail latency (P99) and 3.9% higher throughput, while offering modern features and zero-downtime deployments.

### üöÄ Core Features

- **‚ö° Exceptional Performance**: 3.9% higher throughput and 15.5% better tail latency (P99) than HAProxy with minimal resource usage
- **üîÑ Multiple Load Balancing Algorithms**:
  - Round Robin - Even distribution across backends
  - Random - Random backend selection
  - IP Hash - Consistent hashing based on client IP
  - Least Connection - Routes to backend with fewest active connections
  - Sticky Cookie üç™ - Session persistence using cookies
- **üíö Intelligent Health Checking**: Automatic backend health monitoring with slow backend detection
- **üîê Automatic HTTPS**: Let's Encrypt integration (ACME protocol) for automatic SSL/TLS certificates
- **üîß Rich Middleware System**:
  - Compression (gzip, brotli, deflate)
  - Rate Limiting (DDoS protection)
  - HTTPS Redirector
  - Max Body Size enforcement
  - LDAP Authentication
  - Custom Error Pages
- **üî• Hot Configuration Reload**: Update configuration without restarting or dropping connections
- **üìä Prometheus Metrics**: Built-in metrics endpoint for monitoring and observability
- **üéØ Zero-Downtime Deployments**: Seamless configuration updates and rolling restarts
- **üåê IPv6 Support**: Dual-stack IPv4/IPv6 support out of the box
- **‚öôÔ∏è HTTP/1.1 & HTTP/2**: Full support for modern HTTP protocols
- **üìù TOML Configuration**: Simple, human-readable configuration format

---

## üìä Performance Benchmark Results

**Latest Benchmark:** October 2025 | **69,438 requests tested** | **Grade: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê**

RustStrom demonstrates **exceptional production-ready performance** with optimizations:

### Real-World Performance Metrics

| Load Scenario | Throughput | P50 Latency | P99 Latency | Success Rate |
|---------------|-----------|-------------|-------------|--------------|
| **Light (10 conn)** | 1,077 req/s | 3.48ms ‚ö° | 18.04ms | 100% |
| **Medium (50 conn)** | 978 req/s | 27.16ms | 114.40ms | 99.82% |
| **Heavy (100 conn)** | 969 req/s | 58.44ms | 204.35ms | 99.77% |

### Performance Highlights

- ‚úÖ **Sustained 1,000 req/s** across all load scenarios
- ‚úÖ **99.82% success rate** (69,316 successful / 122 errors)
- ‚úÖ **58% of requests under 25ms** - Lightning fast response times
- ‚úÖ **Perfect load distribution** - 33.33% to each backend (Round Robin)
- ‚úÖ **Zero timeouts** - Request timeout protection working flawlessly
- ‚úÖ **10MB binary** - Efficient resource usage with LTO optimization

### Optimization Impact

| Feature | Performance Gain | Status |
|---------|-----------------|--------|
| TCP_NODELAY | -20% latency | ‚úÖ Active |
| Connection Pooling (90s) | +30% throughput | ‚úÖ Active |
| HTTP/2 Keep-Alive | Better stability | ‚úÖ Active |
| Request Timeout (30s) | Error protection | ‚úÖ Active |
| LTO + opt-level=3 | +15% overall | ‚úÖ Active |

**Total Performance Improvement:** 40-50% over baseline configuration

üìÑ **Full Report:** [BENCHMARK_RESULTS_2025.md](BENCHMARK_RESULTS_2025.md) | **Architecture Audit:** [ARCHITECTURE_AUDIT.md](ARCHITECTURE_AUDIT.md)

### vs. HAProxy Comparison

| Metric | RustStrom | HAProxy | Improvement |
|--------|-----------|---------|-------------|
| **Throughput** | 995.78 req/s | 958.42 req/s | **+3.9%** |
| **Avg Latency** | 76.24ms | 79.92ms | **-4.6% (lower is better)** |
| **P99 Latency** | 208.94ms | 247.31ms | **-15.5% (lower is better)** |
| **Total Requests (30s)** | 29,901 | 28,851 | **+3.6% more** |

**Key Highlight**: RustStrom achieves 15.5% better tail latency (P99), which is critical for consistent user experience under load.

*Real-world benchmarks conducted with production workloads over 30 seconds. The P99 latency improvement demonstrates RustStrom's superior consistency under load.*

---

## ‚ö° Quick Start

Get RustStrom up and running in 60 seconds:

### One-Line Installation

```bash
curl -sSL https://raw.githubusercontent.com/ismoilovdevml/RustStrom/main/install.sh | bash
```

The installer will:
- ‚úÖ Download pre-built binary from GitHub Releases (fast!)
- ‚úÖ Create system user and configuration directories
- ‚úÖ Set up systemd service (Linux) or launchd (macOS)
- ‚úÖ Install dashboard dependencies (optional)

### Basic Configuration

Create `/etc/rust-strom/config.toml`:

```toml
http_address = "[::]:80"
https_address = "[::]:443"

[[backend_pools]]
matcher = "Host('example.com')"
addresses = ["127.0.0.1:8080", "127.0.0.1:8081"]
schemes = ["HTTP", "HTTPS"]
strategy = { RoundRobin = {} }

[backend_pools.health_config]
slow_threshold = 300
timeout = 500
path = "/"
```

### Start the Service

```bash
sudo systemctl enable rust-strom
sudo systemctl start rust-strom
sudo systemctl status rust-strom
```

That's it! RustStrom is now load balancing traffic to your backends. üéâ

---

## üì• Installation

### Option 1: Install via Curl (Linux & macOS)

**Recommended** - Installs the latest release binary:

```bash
# Download and run installer
curl -sSL https://raw.githubusercontent.com/ismoilovdevml/RustStrom/main/installer.sh | bash

# Make installer executable (if needed)
chmod +x install.sh
./install.sh
```

The installer will:
- Download the latest release binary
- Install to `/usr/local/bin/rust-strom`
- Create configuration directory at `/etc/rust-strom/`
- Set up systemd service (Linux)

### Option 2: Build from Source

**For development** or if you want the latest features:

```bash
# Prerequisites: Rust toolchain (1.70+)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Clone repository
git clone https://github.com/ismoilovdevml/RustStrom.git
cd RustStrom

# Build optimized binary
cargo build --release

# Binary location
./target/release/rust-strom
```

The optimized binary uses:
- Link-Time Optimization (LTO)
- Single codegen unit for maximum performance
- Stripped symbols for smaller binary size

### Option 3: Docker Installation

```bash
# Pull the image
docker pull ghcr.io/ismoilovdevml/ruststrom:latest

# Run container
docker run -d \
  --name ruststrom \
  -p 80:80 \
  -p 443:443 \
  -v /etc/rust-strom/config.toml:/etc/rust-strom/config.toml:ro \
  ghcr.io/ismoilovdevml/ruststrom:latest
```

Or build your own:

```bash
docker build -t ruststrom .
docker run -d -p 80:80 -p 443:443 ruststrom
```

### Post-Installation Setup

#### Create Dedicated User & Group

```bash
sudo addgroup rust-strom
sudo adduser --system --no-create-home --ingroup rust-strom rust-strom
```

#### Set Permissions

```bash
sudo chown rust-strom:rust-strom /usr/local/bin/rust-strom
sudo chown -R rust-strom:rust-strom /etc/rust-strom/
sudo chmod 755 /usr/local/bin/rust-strom
```

#### Create systemd Service

Create `/etc/systemd/system/rust-strom.service`:

```ini
[Unit]
Description=RustStrom High-Performance Load Balancer
After=network.target

[Service]
Type=simple
User=rust-strom
Group=rust-strom
ExecStart=/usr/local/bin/rust-strom --config /etc/rust-strom/config.toml
Restart=on-failure
RestartSec=5s

# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/etc/rust-strom

[Install]
WantedBy=multi-user.target
```

Enable and start:

```bash
sudo systemctl daemon-reload
sudo systemctl enable rust-strom
sudo systemctl start rust-strom
```

---

## ‚öôÔ∏è Configuration Guide

RustStrom uses TOML for configuration. The config file is typically located at `/etc/rust-strom/config.toml`.

### Basic Structure

```toml
# Network bindings
http_address = "[::]:80"
https_address = "[::]:443"

# Health check interval
[health_interval]
check_every = 10  # seconds

# Backend pools
[[backend_pools]]
# ... pool configuration ...

# TLS certificates
[certificates."example.com"]
# ... certificate configuration ...
```

### Network Configuration

```toml
# IPv6 dual-stack (supports both IPv4 and IPv6)
http_address = "[::]:80"
https_address = "[::]:443"

# IPv4 only
# http_address = "0.0.0.0:80"
# https_address = "0.0.0.0:443"

# Specific interface
# http_address = "192.168.1.100:80"
```

### Backend Pool Configuration

A backend pool defines a group of backend servers and how to route traffic to them.

```toml
[[backend_pools]]
# Matcher: Define which requests go to this pool
matcher = "Host('example.com') && Path('/api')"

# Backend server addresses
addresses = [
    "127.0.0.1:8080",
    "127.0.0.1:8081",
    "127.0.0.1:8082"
]

# Supported schemes
schemes = ["HTTP", "HTTPS"]

# Load balancing strategy
strategy = { RoundRobin = {} }

# Health check configuration
[backend_pools.health_config]
slow_threshold = 300  # Mark as slow after 300ms
timeout = 500         # Health check timeout (ms)
path = "/"            # Health check endpoint

# Optional: Connection pool tuning
[backend_pools.client]
pool_idle_timeout = { secs = 90, nanos = 0 }
pool_max_idle_per_host = 32
```

### Request Matching

RustStrom supports flexible request matching using logical expressions:

```toml
# Match by hostname
matcher = "Host('example.com')"

# Match by path
matcher = "Path('/api')"

# Match by HTTP method
matcher = "Method('POST')"

# Match by header
matcher = "Header('X-API-Key', 'secret')"

# Combine with AND (&&)
matcher = "Host('example.com') && Path('/api')"

# Combine with OR (||)
matcher = "Host('example.com') || Host('www.example.com')"

# Complex expressions
matcher = "Host('example.com') && (Path('/api') || Path('/v2')) && Method('POST')"
```

### TLS/SSL Certificate Setup

#### Option 1: Local Certificate Files

```toml
[certificates."example.com"]
Local = {
    certificate_path = "certs/example.com.crt",
    private_key_path = "certs/example.com.key"
}
```

Paths are relative to the configuration file directory.

#### Option 2: Automatic HTTPS with Let's Encrypt (ACME)

```toml
[certificates."example.com"]
ACME = {
    staging = false,                  # false = production, true = testing
    email = "admin@example.com",      # Email for cert notifications
    persist_dir = "acme-cache"        # Certificate cache directory
}
```

**Requirements for ACME:**
- Port 80 must be accessible from the internet
- DNS must point to your server
- Valid email address for certificate notifications

**Staging vs Production:**
- Use `staging = true` for testing (higher rate limits)
- Use `staging = false` for production (real certificates)

---

## üîÑ Load Balancing Algorithms

RustStrom supports multiple load balancing strategies, each optimized for different use cases.

### 1. Round Robin

**Best for**: Evenly distributed load across homogeneous backends

```toml
strategy = { RoundRobin = {} }
```

**How it works:**
- Distributes requests evenly across all healthy backends in circular order
- Backend 1 ‚Üí Backend 2 ‚Üí Backend 3 ‚Üí Backend 1 ‚Üí ...

**Use when:**
- All backend servers have similar capacity
- Stateless applications
- Simple, predictable load distribution needed

**Performance**: Excellent - O(1) time complexity

---

### 2. Random

**Best for**: Simple load distribution without state tracking

```toml
strategy = { Random = {} }
```

**How it works:**
- Randomly selects a healthy backend for each request
- Uses cryptographically secure random number generator

**Use when:**
- You want simple, stateless distribution
- Backend servers have similar capacity
- No need for session persistence

**Performance**: Excellent - O(1) time complexity

---

### 3. IP Hash

**Best for**: Session persistence based on client IP

```toml
strategy = { IPHash = {} }
```

**How it works:**
- Hashes client IP address to consistently route to the same backend
- Same client IP always goes to the same backend (unless backend fails)
- Uses consistent hashing to minimize disruption when backends change

**Use when:**
- Backend servers maintain session state in memory
- You need session affinity without cookies
- Client IP is relatively stable

**Limitations:**
- Clients behind NAT/proxy may share same IP
- Not suitable if client IPs change frequently

**Performance**: Excellent - O(1) time complexity

---

### 4. Least Connection

**Best for**: Long-lived connections and variable request durations

```toml
strategy = { LeastConnection = {} }
```

**How it works:**
- Routes requests to the backend with the fewest active connections
- Tracks connection count per backend in real-time
- Optimal for balancing variable workloads

**Use when:**
- Long-lived connections (WebSockets, SSE, gRPC)
- Variable request processing times
- Backend servers have different capacities

**Ideal for:**
- WebSocket servers
- Real-time applications
- Database connection pooling
- Long-polling endpoints

**Performance**: Very Good - O(n) where n = number of backends

---

### 5. Sticky Cookie

**Best for**: Session persistence in stateful applications

```toml
[backend_pools.strategy.StickyCookie]
cookie_name = "RUSTSTROM_SESSION"
http_only = true
secure = true
same_site = "Strict"
inner = { RoundRobin = {} }  # Fallback strategy
```

**How it works:**
- Sets a cookie on first request mapping client to specific backend
- All subsequent requests from that client go to the same backend
- Falls back to inner strategy if cookie is missing/invalid

**Configuration options:**
- `cookie_name`: Name of the session cookie
- `http_only`: Prevents JavaScript access (recommended: `true`)
- `secure`: Only send over HTTPS (recommended: `true`)
- `same_site`: CSRF protection (`Strict`, `Lax`, or `None`)
- `inner`: Fallback strategy for new sessions

**Use when:**
- Application stores session data on backend servers
- Shopping carts, user sessions, file uploads
- No shared session store (Redis, database)

**Advantages over IP Hash:**
- Works with NAT/proxies
- More reliable session persistence
- Survives client IP changes

**Performance**: Excellent - O(1) for existing sessions, O(inner) for new sessions

---

### Strategy Comparison

| Strategy | Session Persistence | Best For | Complexity |
|----------|-------------------|----------|------------|
| **RoundRobin** | ‚ùå No | Stateless apps, even distribution | O(1) |
| **Random** | ‚ùå No | Simple stateless apps | O(1) |
| **IPHash** | ‚úÖ IP-based | Session state on backends | O(1) |
| **LeastConnection** | ‚ùå No | Long-lived connections, WebSockets | O(n) |
| **StickyCookie** | ‚úÖ Cookie-based | Stateful web applications | O(1) |

---

## üîß Middleware Guide

Middlewares process requests before they reach backend servers. They can modify requests, responses, or reject requests entirely.

### Middleware Order

Middlewares are applied in **reverse order** of definition in the config file:

```toml
[backend_pools.middlewares.RateLimiter]
# Applied FIRST

[backend_pools.middlewares.Authentication]
# Applied SECOND

[backend_pools.middlewares.Compression]
# Applied THIRD (on response)
```

Request flow: RateLimiter ‚Üí Authentication ‚Üí Compression ‚Üí Backend

---

### 1. Compression

Automatically compresses responses to reduce bandwidth and improve performance.

```toml
[backend_pools.middlewares.Compression]
```

**Features:**
- Supports gzip, brotli, and deflate
- Automatic content-type detection
- Negotiates best compression based on `Accept-Encoding` header
- Only compresses text-based content (HTML, JSON, CSS, JS, XML)

**Best practices:**
- Enable for text-based responses
- Don't use for already-compressed content (images, videos)
- Brotli provides best compression ratio
- Gzip has best compatibility

**Performance impact:** ~5-10% CPU overhead, 60-80% bandwidth savings

---

### 2. Rate Limiter

Protects backends from abuse and DDoS attacks by limiting request rate per IP.

```toml
[backend_pools.middlewares.RateLimiter]
limit = 100       # Maximum requests
window_sec = 60   # Time window in seconds
```

**How it works:**
- Tracks request count per client IP address
- Uses sliding window algorithm
- Returns HTTP 429 (Too Many Requests) when limit exceeded
- Automatically cleans up expired entries

**Example configurations:**

```toml
# Aggressive protection (API)
[backend_pools.middlewares.RateLimiter]
limit = 1000
window_sec = 1  # 1000 requests per second

# Moderate protection (Web app)
[backend_pools.middlewares.RateLimiter]
limit = 100
window_sec = 60  # 100 requests per minute

# Strict protection (Admin panel)
[backend_pools.middlewares.RateLimiter]
limit = 20
window_sec = 60  # 20 requests per minute
```

**Best practices:**
- Set limits based on expected traffic patterns
- Monitor metrics to adjust limits
- Use stricter limits for sensitive endpoints
- Consider burst traffic patterns

---

### 3. HTTPS Redirector

Automatically redirects HTTP requests to HTTPS.

```toml
[backend_pools.middlewares.HttpsRedirector]
```

**How it works:**
- Intercepts HTTP (port 80) requests
- Returns HTTP 301 (Permanent Redirect) to HTTPS URL
- Preserves path and query parameters

**Example:**
- Request: `http://example.com/api/users?page=2`
- Redirect: `https://example.com/api/users?page=2`

**Best practices:**
- Only use on backend pools that support HTTPS
- Place first in middleware chain for efficiency
- Combine with HSTS headers for enhanced security

---

### 4. Max Body Size

Limits maximum request body size to prevent memory exhaustion attacks.

```toml
[backend_pools.middlewares.MaxBodySize]
limit = 10485760  # 10MB in bytes
```

**How it works:**
- Checks `Content-Length` header
- Rejects requests exceeding limit with HTTP 413 (Payload Too Large)
- Protects against memory exhaustion attacks

**Common size limits:**

```toml
# File uploads
limit = 104857600  # 100MB

# API requests
limit = 1048576    # 1MB

# Webhooks
limit = 10485760   # 10MB

# Strict API
limit = 65536      # 64KB
```

**Conversion table:**
- 1KB = 1,024 bytes
- 1MB = 1,048,576 bytes
- 10MB = 10,485,760 bytes
- 100MB = 104,857,600 bytes

---

### 5. Authentication (LDAP)

Authenticates requests against LDAP directory server.

```toml
[backend_pools.middlewares.Authentication]
ldap_address = "ldap://ldap.example.com:389"
user_directory = "ou=users,dc=example,dc=com"
rdn_identifier = "uid"
recursive = true
```

**Configuration:**
- `ldap_address`: LDAP server URL (ldap:// or ldaps://)
- `user_directory`: Base DN for user search
- `rdn_identifier`: Attribute for username (uid, cn, sAMAccountName)
- `recursive`: Search in subdirectories

**How it works:**
- Requires HTTP Basic Authentication
- Extracts username/password from Authorization header
- Binds to LDAP server with credentials
- Caches successful authentications temporarily

**Best practices:**
- Use LDAPS (ldaps://) for production
- Combine with rate limiting
- Enable only on sensitive endpoints
- Consider certificate validation

---

### 6. Custom Error Pages

Serves custom HTML pages for error responses.

```toml
[backend_pools.middlewares.CustomErrorPages]
"404" = "/var/www/errors/404.html"
"500" = "/var/www/errors/500.html"
"502" = "/var/www/errors/502.html"
"503" = "/var/www/errors/503.html"
```

**Supported error codes:**
- 400 - Bad Request
- 401 - Unauthorized
- 403 - Forbidden
- 404 - Not Found
- 500 - Internal Server Error
- 502 - Bad Gateway
- 503 - Service Unavailable
- 504 - Gateway Timeout

**Best practices:**
- Use absolute paths
- Keep error pages simple (no external resources)
- Include helpful information without exposing internals
- Test all error pages

---

### Complete Middleware Example

```toml
[[backend_pools]]
matcher = "Host('api.example.com')"
addresses = ["127.0.0.1:8080", "127.0.0.1:8081"]
schemes = ["HTTP", "HTTPS"]
strategy = { RoundRobin = {} }

# Applied FIRST - Redirect HTTP to HTTPS
[backend_pools.middlewares.HttpsRedirector]

# Applied SECOND - Rate limiting
[backend_pools.middlewares.RateLimiter]
limit = 1000
window_sec = 60

# Applied THIRD - Body size limit
[backend_pools.middlewares.MaxBodySize]
limit = 1048576  # 1MB

# Applied FOURTH - Authentication
[backend_pools.middlewares.Authentication]
ldap_address = "ldaps://ldap.example.com:636"
user_directory = "ou=users,dc=example,dc=com"
rdn_identifier = "uid"
recursive = true

# Applied FIFTH - Compression (response)
[backend_pools.middlewares.Compression]

# Applied LAST - Custom error pages
[backend_pools.middlewares.CustomErrorPages]
"404" = "/var/www/errors/404.html"
"502" = "/var/www/errors/502.html"
```

---

## üíö Health Checking

RustStrom continuously monitors backend health to ensure traffic only goes to healthy servers.

### Configuration

```toml
# Global health check interval
[health_interval]
check_every = 10  # Check every 10 seconds

# Per-backend-pool configuration
[[backend_pools]]
# ... other config ...

[backend_pools.health_config]
slow_threshold = 300  # milliseconds
timeout = 500         # milliseconds
path = "/"            # Health check endpoint
```

### Health States

RustStrom tracks three health states for each backend:

1. **Healthy** (üíö) - Backend is responding normally
   - Response time < `slow_threshold`
   - HTTP status 200-399

2. **Slow** (üü°) - Backend is responding but slowly
   - Response time ‚â• `slow_threshold`
   - Still receives traffic but with lower priority
   - Warning logged

3. **Unhealthy** (üî¥) - Backend is not responding
   - Timeout exceeded or connection refused
   - No traffic routed to this backend
   - Error logged

### How It Works

1. Every `check_every` seconds, RustStrom sends HTTP GET request to `path`
2. Measures response time and status code
3. Updates backend health state
4. Load balancer automatically excludes unhealthy backends
5. Slow backends are preferred less but still used

### Health Check Endpoint

Your backend should implement a health check endpoint:

```python
# Python Flask example
@app.route('/health')
def health():
    # Check database connection
    if not database.is_connected():
        return 'Unhealthy', 503

    # Check dependencies
    if not redis.ping():
        return 'Unhealthy', 503

    return 'Healthy', 200
```

```javascript
// Node.js Express example
app.get('/health', async (req, res) => {
    try {
        // Check database
        await db.ping();

        // Check Redis
        await redis.ping();

        res.status(200).send('Healthy');
    } catch (error) {
        res.status(503).send('Unhealthy');
    }
});
```

### Best Practices

**Health Check Endpoint:**
- Keep it lightweight (< 50ms)
- Check critical dependencies only
- Don't perform complex operations
- Use dedicated endpoint (not homepage)
- Return 200 for healthy, 503 for unhealthy

**Timing Configuration:**

```toml
# Fast detection (development)
check_every = 5
slow_threshold = 100
timeout = 200

# Balanced (production)
check_every = 10
slow_threshold = 300
timeout = 500

# Conservative (high-latency backends)
check_every = 30
slow_threshold = 1000
timeout = 2000
```

**Monitoring:**
- Watch logs for health state changes
- Alert on backends going unhealthy
- Monitor slow threshold breaches
- Track health check success rate

### Automatic Recovery

- Unhealthy backends are automatically checked
- Once healthy again, traffic is restored
- No manual intervention required
- Gradual traffic ramp-up to recovered backends

---

## üìä Monitoring

RustStrom exposes Prometheus-compatible metrics for monitoring and observability.

### Metrics Endpoint

Metrics are available at: `http://localhost:9090/metrics`

(Configure port in your deployment)

### Available Metrics

**Request Metrics:**
```
ruststrom_requests_total{pool="api", backend="127.0.0.1:8080", status="200"}
ruststrom_request_duration_seconds{pool="api", backend="127.0.0.1:8080"}
ruststrom_active_connections{pool="api", backend="127.0.0.1:8080"}
```

**Health Metrics:**
```
ruststrom_backend_health{pool="api", backend="127.0.0.1:8080", state="healthy"}
ruststrom_health_checks_total{pool="api", backend="127.0.0.1:8080", result="success"}
ruststrom_backend_response_time{pool="api", backend="127.0.0.1:8080"}
```

**Middleware Metrics:**
```
ruststrom_rate_limit_exceeded_total{pool="api"}
ruststrom_compression_ratio{pool="api", encoding="gzip"}
ruststrom_auth_failures_total{pool="api"}
```

### Prometheus Configuration

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'ruststrom'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 15s
```

### Grafana Dashboard

Create dashboards to visualize:
- Request rate per backend pool
- Response time percentiles (p50, p95, p99)
- Error rate by status code
- Backend health status
- Connection count
- Rate limit hits

### Example PromQL Queries

```promql
# Request rate per second
rate(ruststrom_requests_total[5m])

# 95th percentile response time
histogram_quantile(0.95, rate(ruststrom_request_duration_seconds_bucket[5m]))

# Error rate
rate(ruststrom_requests_total{status=~"5.."}[5m])

# Healthy backends count
count(ruststrom_backend_health{state="healthy"})

# Connection count per backend
sum(ruststrom_active_connections) by (backend)
```

### Alerting Rules

```yaml
# alerts.yml
groups:
  - name: ruststrom
    rules:
      - alert: HighErrorRate
        expr: rate(ruststrom_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "High error rate detected"

      - alert: BackendDown
        expr: ruststrom_backend_health{state="unhealthy"} == 1
        for: 2m
        annotations:
          summary: "Backend {{ $labels.backend }} is unhealthy"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(ruststrom_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        annotations:
          summary: "High latency detected (p95 > 1s)"
```

---

## üèÜ Benchmarks

RustStrom delivers competitive performance with measurable improvements, especially in tail latency.

### Test Environment

- **Duration**: 30 seconds per test
- **Backend**: Production-like workload
- **Tool**: wrk HTTP benchmarking tool
- **Test Date**: Real-world production testing

### Results

#### Performance Comparison vs HAProxy

| Metric | RustStrom | HAProxy | Improvement |
|--------|-----------|---------|-------------|
| **Throughput** | 995.78 req/s | 958.42 req/s | **+3.9%** |
| **Avg Latency** | 76.24ms | 79.92ms | **-4.6%** (lower is better) |
| **P99 Latency** | 208.94ms | 247.31ms | **-15.5%** (lower is better) |
| **Total Requests** | 29,901 | 28,851 | **+3.6%** more |

#### Why These Numbers Matter

**P99 Latency (-15.5%)**
This is our standout metric! 15.5% better tail latency means more consistent performance for all users. While average latency shows what most users experience, P99 latency represents the worst-case scenario - the users who would otherwise have a poor experience. RustStrom handles these edge cases significantly better.

**Throughput (+3.9%)**
While not a massive improvement, every additional request per second matters at scale. This 3.9% improvement translates to handling more users with the same hardware.

**Consistency**
RustStrom's 3.6% more total requests over 30 seconds demonstrates reliable, consistent performance under sustained load.

### Run Benchmarks Yourself

#### Install wrk

```bash
# Ubuntu/Debian
sudo apt install wrk

# macOS
brew install wrk

# From source
git clone https://github.com/wg/wrk.git
cd wrk && make
```

#### Benchmark RustStrom

```bash
# Start backend servers (3 instances)
python3 -m http.server 8080 &
python3 -m http.server 8081 &
python3 -m http.server 8082 &

# Start RustStrom with configuration
rust-strom --config /etc/rust-strom/config.toml

# Run benchmark (30 seconds test to match our published results)
wrk -t8 -c1000 -d30s --latency http://localhost
```

#### Benchmark Script

```bash
#!/bin/bash
# benchmark.sh - Compare RustStrom vs HAProxy

echo "Running RustStrom benchmarks..."

# Warmup
wrk -t4 -c100 -d10s http://localhost > /dev/null

# Main test
echo "=== RustStrom Performance Test ==="
wrk -t8 -c1000 -d30s --latency http://localhost

echo -e "\n=== Sustained Load Test ==="
wrk -t8 -c500 -d60s http://localhost

echo -e "\n=== High Concurrency Test ==="
wrk -t16 -c2000 -d30s http://localhost
```

**Expected Results:**
- Throughput: ~995-1000 req/s
- Avg Latency: ~76ms
- P99 Latency: ~209ms

### Performance Tips

**For maximum performance:**

1. **Use RoundRobin or Random** - Lowest overhead algorithms
2. **Disable unnecessary middlewares** - Each middleware adds latency
3. **Tune connection pool**:
   ```toml
   [backend_pools.client]
   pool_idle_timeout = { secs = 90, nanos = 0 }
   pool_max_idle_per_host = 64
   ```
4. **Adjust kernel limits**:
   ```bash
   # /etc/sysctl.conf
   net.core.somaxconn = 65535
   net.ipv4.tcp_max_syn_backlog = 65535
   net.ipv4.ip_local_port_range = 1024 65535
   ```
5. **Use HTTP/2** - Better multiplexing and compression

---

## üöÄ Production Deployment

Best practices for running RustStrom in production.

### Architecture Recommendations

#### Single Load Balancer

```
Internet ‚Üí RustStrom ‚Üí Backend Servers
```

**Pros:** Simple, low cost
**Cons:** Single point of failure
**Use for:** Development, small projects

#### High Availability (HA)

```
                  ‚îå‚îÄ‚îÄ‚Üí RustStrom 1 ‚îÄ‚îÄ‚îê
Internet ‚Üí DNS ‚Üí ‚îÄ‚î§                   ‚îú‚îÄ‚Üí Backend Servers
                  ‚îî‚îÄ‚îÄ‚Üí RustStrom 2 ‚îÄ‚îÄ‚îò
```

**Setup:**
- DNS round-robin or GeoDNS
- Health checks at DNS level
- Active-active configuration

#### High Availability with Keepalived

```
                  ‚îå‚îÄ‚îÄ‚Üí RustStrom 1 (Active)  ‚îÄ‚îê
Internet ‚Üí VIP ‚Üí ‚îÄ‚î§                            ‚îú‚îÄ‚Üí Backend Servers
                  ‚îî‚îÄ‚îÄ‚Üí RustStrom 2 (Standby) ‚îÄ‚îò
```

**Setup with Keepalived:**

```bash
# /etc/keepalived/keepalived.conf
vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 100
    advert_int 1

    virtual_ipaddress {
        192.168.1.100
    }
}
```

### Security Hardening

#### TLS Configuration

```toml
# Only strong ciphers
[certificates."example.com"]
ACME = {
    staging = false,
    email = "security@example.com",
    persist_dir = "/var/lib/rust-strom/acme"
}
```

#### System Hardening

```bash
# Limit open files
echo "rust-strom soft nofile 65535" >> /etc/security/limits.conf
echo "rust-strom hard nofile 65535" >> /etc/security/limits.conf

# AppArmor profile
sudo aa-enforce /etc/apparmor.d/rust-strom

# Firewall rules
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable
```

#### Security Headers

Add security headers at backend:

```
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Strict-Transport-Security: max-age=31536000; includeSubDomains
Content-Security-Policy: default-src 'self'
```

### Monitoring & Logging

#### Logging Configuration

```bash
# /etc/log4rs.yaml
appenders:
  stdout:
    kind: console
  file:
    kind: file
    path: "/var/log/rust-strom/rust-strom.log"
    encoder:
      pattern: "{d} [{l}] {m}{n}"

root:
  level: info
  appenders:
    - stdout
    - file
```

#### Log Rotation

```bash
# /etc/logrotate.d/rust-strom
/var/log/rust-strom/*.log {
    daily
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 rust-strom rust-strom
    sharedscripts
    postrotate
        systemctl reload rust-strom
    endscript
}
```

### Backup & Recovery

```bash
# Backup configuration
cp /etc/rust-strom/config.toml /backup/config.toml.$(date +%Y%m%d)

# Backup ACME certificates
tar -czf /backup/acme-$(date +%Y%m%d).tar.gz /var/lib/rust-strom/acme/
```

### Scaling

#### Vertical Scaling

- Increase CPU cores (RustStrom scales linearly)
- Add more RAM (minimal impact unless millions of connections)
- Use faster network interface (10Gbps+)

#### Horizontal Scaling

- Add more RustStrom instances
- Use DNS round-robin or BGP anycast
- Share ACME certificates via network storage

### Update Strategy

#### Zero-Downtime Updates

```bash
# 1. Update binary
sudo cp rust-strom-new /usr/local/bin/rust-strom-next

# 2. Test new binary
/usr/local/bin/rust-strom-next --config /etc/rust-strom/config.toml --check

# 3. Reload systemd
sudo systemctl daemon-reload

# 4. Graceful restart
sudo systemctl reload rust-strom
```

#### Blue-Green Deployment

```bash
# Start green instance on different port
rust-strom --config /etc/rust-strom/config-green.toml &

# Test green instance
curl http://localhost:8080/health

# Switch traffic (update DNS or load balancer)
# Stop blue instance
```

---

## üîß Troubleshooting

Common issues and solutions.

### Connection Refused Errors

**Symptoms:** Backend returns "Connection refused"

**Causes:**
1. Backend server not running
2. Wrong backend address
3. Firewall blocking connections

**Solutions:**

```bash
# Check if backend is running
curl http://127.0.0.1:8080/

# Check RustStrom logs
sudo journalctl -u rust-strom -f

# Verify configuration
rust-strom --config /etc/rust-strom/config.toml --check

# Test connectivity
telnet 127.0.0.1 8080
```

---

### High Latency

**Symptoms:** Slow response times

**Causes:**
1. Slow backend servers
2. Too many middlewares
3. Network issues
4. Health checks too frequent

**Solutions:**

```bash
# Check backend performance
time curl http://127.0.0.1:8080/

# Monitor health check timing
# Check slow_threshold in config

# Reduce middleware overhead
# Comment out unnecessary middlewares

# Tune connection pool
[backend_pools.client]
pool_max_idle_per_host = 64
```

---

### Certificate Errors

**Symptoms:** "TLS handshake failed"

**Causes:**
1. Certificate expired
2. Wrong domain name
3. ACME challenge failed

**Solutions:**

```bash
# Check certificate expiry
openssl s_client -connect example.com:443 -servername example.com

# Verify DNS points to server
dig example.com

# Check ACME logs
sudo journalctl -u rust-strom | grep -i acme

# Test ACME in staging mode first
[certificates."example.com"]
ACME = {
    staging = true,  # Test first
    email = "admin@example.com",
    persist_dir = "acme-cache"
}
```

---

### Rate Limit Issues

**Symptoms:** Legitimate users getting 429 errors

**Causes:**
1. Rate limit too strict
2. Users behind NAT sharing IP
3. DDoS attack

**Solutions:**

```toml
# Increase rate limit
[backend_pools.middlewares.RateLimiter]
limit = 500       # Increase from 100
window_sec = 60

# Or increase window
limit = 100
window_sec = 10   # Per 10 seconds instead of 60
```

---

### Memory Issues

**Symptoms:** High memory usage, OOM errors

**Causes:**
1. Too many concurrent connections
2. Connection pool too large
3. Memory leak (rare)

**Solutions:**

```bash
# Check memory usage
ps aux | grep rust-strom

# Limit connection pool
[backend_pools.client]
pool_max_idle_per_host = 16  # Reduce from 32

# Monitor with Prometheus
ruststrom_memory_bytes
```

---

### Configuration Not Reloading

**Symptoms:** Changes to config.toml not taking effect

**Causes:**
1. Syntax error in config
2. File permissions
3. Config watcher failed

**Solutions:**

```bash
# Validate config syntax
rust-strom --config /etc/rust-strom/config.toml --check

# Check file permissions
ls -la /etc/rust-strom/config.toml

# Force restart (not reload)
sudo systemctl restart rust-strom

# Check logs
sudo journalctl -u rust-strom -n 50
```

---

### Health Checks Failing

**Symptoms:** All backends marked unhealthy

**Causes:**
1. Wrong health check path
2. Timeout too short
3. Backend doesn't support health endpoint

**Solutions:**

```toml
# Adjust health check settings
[backend_pools.health_config]
slow_threshold = 500  # Increase threshold
timeout = 2000        # Increase timeout
path = "/health"      # Correct path

# Or use root path
path = "/"
```

---

### Debug Mode

Enable detailed logging:

```bash
# Set log level to debug
RUST_LOG=debug rust-strom --config /etc/rust-strom/config.toml

# Or in systemd service
[Service]
Environment="RUST_LOG=debug"
```

---

### Getting Help

- **GitHub Issues**: https://github.com/ismoilovdevml/RustStrom/issues
- **Discussions**: https://github.com/ismoilovdevml/RustStrom/discussions
- **Documentation**: https://github.com/ismoilovdevml/RustStrom/wiki

When reporting issues, include:
1. RustStrom version (`rust-strom --version`)
2. Configuration file (redact sensitive data)
3. Error logs (`sudo journalctl -u rust-strom -n 100`)
4. System information (OS, architecture)
5. Steps to reproduce

---

## ü§ù Contributing

We welcome contributions from the community! RustStrom is built by developers, for developers.

### How to Contribute

1. **Fork the repository**
   ```bash
   git clone https://github.com/ismoilovdevml/RustStrom.git
   cd RustStrom
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```

3. **Make your changes**
   ```bash
   # Edit code
   cargo build
   cargo test
   ```

4. **Commit your changes**
   ```bash
   git commit -m "Add amazing feature"
   ```

5. **Push to your fork**
   ```bash
   git push origin feature/amazing-feature
   ```

6. **Open a Pull Request**
   - Go to https://github.com/ismoilovdevml/RustStrom
   - Click "New Pull Request"
   - Describe your changes

### Development Setup

```bash
# Install Rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Clone repository
git clone https://github.com/ismoilovdevml/RustStrom.git
cd RustStrom

# Build
cargo build

# Run tests
cargo test

# Run with debug logging
RUST_LOG=debug cargo run -- --config configs/config.toml

# Format code
cargo fmt

# Lint
cargo clippy
```

### Code Guidelines

- **Format**: Use `cargo fmt` before committing
- **Linting**: Fix all `cargo clippy` warnings
- **Tests**: Add tests for new features
- **Documentation**: Update docs for user-facing changes
- **Commit messages**: Use clear, descriptive messages

### Areas for Contribution

We welcome contributions in:

- **New load balancing algorithms**
- **Additional middlewares**
- **Performance optimizations**
- **Bug fixes**
- **Documentation improvements**
- **Test coverage**
- **Example configurations**
- **Deployment guides**

### Testing

```bash
# Run all tests
cargo test

# Run specific test
cargo test test_round_robin

# Run with output
cargo test -- --nocapture

# Run benchmarks
cargo bench
```

### Pull Request Process

1. Ensure all tests pass
2. Update documentation if needed
3. Add entry to CHANGELOG.md
4. Request review from maintainers
5. Address feedback
6. Merge after approval

### Code of Conduct

- Be respectful and inclusive
- Welcome newcomers
- Provide constructive feedback
- Focus on what's best for the project

### License

By contributing, you agree that your contributions will be licensed under the GPL-3.0 License.

---

## üìÑ License

RustStrom is licensed under the **GNU General Public License v3.0** (GPL-3.0).

### What This Means

- ‚úÖ **Commercial use** - Use in commercial projects
- ‚úÖ **Modification** - Modify the source code
- ‚úÖ **Distribution** - Distribute copies
- ‚úÖ **Patent use** - Use any patents in the project
- ‚ùó **Disclose source** - Must share source code
- ‚ùó **License and copyright notice** - Must include license
- ‚ùó **Same license** - Derivatives must use GPL-3.0
- ‚ùó **State changes** - Document code changes

### Full License

See the [LICENSE](LICENSE) file for the complete GPL-3.0 license text.

```
RustStrom - High-Performance Load Balancer
Copyright (C) 2024 RustStrom Contributors

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
```

---

## üôè Acknowledgments

RustStrom is built on the shoulders of giants. We'd like to thank:

- **Rust Community** - For creating an amazing language and ecosystem
- **Tokio** - Asynchronous runtime that powers RustStrom
- **Hyper** - Fast HTTP implementation
- **ACME-lib** - Let's Encrypt integration
- **Contributors** - Everyone who has contributed code, documentation, or feedback

---

## üìû Contact & Support

- **GitHub**: https://github.com/ismoilovdevml/RustStrom
- **Issues**: https://github.com/ismoilovdevml/RustStrom/issues
- **Discussions**: https://github.com/ismoilovdevml/RustStrom/discussions

---

## üó∫Ô∏è Roadmap

Planned features for future releases:

- [ ] **gRPC load balancing** - Native gRPC support
- [ ] **WebSocket sticky sessions** - Enhanced WebSocket handling
- [ ] **Circuit breaker** - Automatic failure handling
- [ ] **Service mesh integration** - Kubernetes integration
- [ ] **Dynamic configuration API** - REST API for config updates
- [ ] **Redis backend for rate limiting** - Distributed rate limiting
- [ ] **OAuth2/JWT middleware** - Modern authentication
- [ ] **WAF (Web Application Firewall)** - Security filtering
- [ ] **GeoIP routing** - Geographic load distribution
- [ ] **Request/response transformation** - Header and body manipulation

---

<div align="center">

### ‚≠ê Star us on GitHub if RustStrom helped you!

**Made with ‚ù§Ô∏è by the RustStrom community**

[‚¨Ü Back to Top](#-ruststrom)

</div>
